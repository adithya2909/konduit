# config/settings.yaml
crawl:
  max_pages: 20
  max_depth: 2
  crawl_delay_ms: 500

index:
  chunk_size: 256
  chunk_overlap: 50
  embedding_model: "sentence-transformers/all-MiniLM-L6-v2"

generation:
  hf_model: "llama-3.1-8b-instant"  # default HF model for generation (change if you want)
  max_new_tokens: 500
  temperature: 0.0
